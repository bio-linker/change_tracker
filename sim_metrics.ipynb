{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The objective of this notebook is to compare several similarity metrics, in the area of biocollections, and envisioning the construction process of a similarity graph\n",
    "\n",
    "### Essential answers (from Dr. Fortes):\n",
    "- % of records with certain % of similarity\n",
    "- % of records with certain % of similarity considering n fields\n",
    "\n",
    "### Some implementation reasoning:\n",
    "- When we talk about similarity, we assume the existence of two strings or a ground true value which is compared to other test values. In the case of biocollection metadata, what to we want to compare to what?\n",
    "- A cross product of all the values of all the terms compared to all the other values seem too costly, computationally.\n",
    "- The similarity that is computed in this notebook does not have any biological knowledge: we do not consider similarity among specimens' families or genus or something similar. This is a general or ignorant procedure, considering the semantic value of the data.\n",
    "\n",
    "### Probabilistic databases: \n",
    "I checked some documentation about probabilistic databases, because they could be a good storage option for the processed data, but the available software I found is outdated or not mature enough. \n",
    "Moreover, most of these databases include probability values for the tuple (tuple-level uncertainty) or for some column (attribute-level uncertainty), not for the relations among values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity analysis of the Scientific name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql.functions import count, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 3858\n"
     ]
    }
   ],
   "source": [
    "dataset = spark.read.parquet(\"./preston-amazon/data-processed/core.parquet\")\n",
    "dataset = dataset.fillna('')\n",
    "N = dataset.count()\n",
    "print(\"Number of rows: \" + str(N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame( columns = ['sc_name', 'count'] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sn = dataset.groupBy(\"`http://rs.tdwg.org/dwc/terms/scientificName`\").count().select(col(\"`http://rs.tdwg.org/dwc/terms/scientificName`\").alias('sc_name'), col('count').alias('n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "708"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sn.count()\n",
    "# Number of different scientific names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that for our collection of 3,858 records, the complete scientific name analysis would imply (708 x 708 / 2) - 708 = 249,924 comparisons.\n",
    "We should think about questions like:\n",
    "- Is it meaningful to conclude that a scientific name is 65% similar to another one?\n",
    "- Is it meaningful to conclude that a date is 70% similar to another one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------+---+\n",
      "|sc_name                                    |n  |\n",
      "+-------------------------------------------+---+\n",
      "|Triportheus angulatus (Spix & Agassiz 1829)|51 |\n",
      "|Pygocentrus nattereri Kner 1858            |49 |\n",
      "|Serrasalmus rhombeus (Linnaeus 1766)       |49 |\n",
      "|Pimelodus blochii Valenciennes 1840        |48 |\n",
      "|Sorubim lima (Bloch & Schneider 1801)      |45 |\n",
      "|Moenkhausia dichroura (Kner 1858)          |43 |\n",
      "|Ageneiosus inermis (Linnaeus 1766)         |43 |\n",
      "|Roeboides affinis (Günther 1868)           |42 |\n",
      "|Schizodon fasciatus Spix & Agassiz 1829    |41 |\n",
      "|Acestrorhynchus gr. lacustris (Lütken 1875)|40 |\n",
      "+-------------------------------------------+---+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_sn.orderBy('count', ascending=False).show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_list = dataset_sn.select('sc_name').rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arocera (Euopta) placens Walker 1867\n"
     ]
    }
   ],
   "source": [
    "print(sn_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyxdameraulevenshtein import normalized_damerau_levenshtein_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rio indistinctus Fortes & Grazia 2000 vs. Rio distinctus Fortes & Grazia 2000\t0.9459459446370602\n",
      "Edessa rufodorsata Silva, Fernandes & Grazia 2006 vs. Edessa virididorsata Silva, Fernandes & Grazia 2006\t0.9019607827067375\n",
      "Gonatopus neotropicus Olmi 1984 vs. Gonatopus neotropicus Olmi 1986\t0.9677419364452362\n",
      "CPU times: user 14.9 s, sys: 0 ns, total: 14.9 s\n",
      "Wall time: 14.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#subset = sn_list[0:100]\n",
    "subset = sn_list\n",
    "i = 0\n",
    "j = 0\n",
    "while i < len(subset):\n",
    "    j = i+1\n",
    "    while j < len(subset):\n",
    "        if (i != j):\n",
    "            sim = 1 - normalized_damerau_levenshtein_distance (subset[i], subset[j])\n",
    "            if (sim > 0.9):\n",
    "                print(subset[i] + \" vs. \" + subset[j] + \"\\t\" + str(sim))\n",
    "        j = j + 1\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In short terms, like scientific name, the Damerau Levenshtein similarity may be more useful than using n-grams.\n",
    "To have a better idea about how to implement it and how to present the results, I believe we should discuss: how do we expect these results are going to be used? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
